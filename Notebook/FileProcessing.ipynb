{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import soundfile as sf\n",
    "from collections import defaultdict\n",
    "import hashlib\n",
    "from pydub.utils import mediainfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_audio_properties(directory):\n",
    "    sample_rate_counts = defaultdict(int)\n",
    "    mono_count = 0\n",
    "    stereo_count = 0\n",
    "    other_channels_count = 0\n",
    "    file_count = 0\n",
    "\n",
    "    # Iterate through all files in the directory (and subdirectories)\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            # Process only common audio file types\n",
    "            if file.lower().endswith(('.wav', '.flac', '.mp3', '.ogg')):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    data, samplerate = sf.read(file_path)\n",
    "                    file_count += 1\n",
    "                    sample_rate_counts[samplerate] += 1\n",
    "\n",
    "                    # Determine the number of channels\n",
    "                    if data.ndim == 1:\n",
    "                        mono_count += 1\n",
    "                    elif data.ndim == 2:\n",
    "                        channels = data.shape[1]\n",
    "                        if channels == 1:\n",
    "                            mono_count += 1\n",
    "                        elif channels == 2:\n",
    "                            stereo_count += 1\n",
    "                        else:\n",
    "                            other_channels_count += 1\n",
    "                    else:\n",
    "                        other_channels_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "    # Print aggregated results\n",
    "    print(f\"Total files processed: {file_count}\")\n",
    "    print(\"Sample Rate Distribution:\")\n",
    "    for sr, count in sample_rate_counts.items():\n",
    "        print(f\"  {sr} Hz: {count} file(s)\")\n",
    "    print(f\"Mono files: {mono_count}\")\n",
    "    print(f\"Stereo files: {stereo_count}\")\n",
    "    print(f\"Other channels: {other_channels_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files processed: 69300\n",
      "Sample Rate Distribution:\n",
      "  16000 Hz: 69300 file(s)\n",
      "Mono files: 69300\n",
      "Stereo files: 0\n",
      "Other channels: 0\n"
     ]
    }
   ],
   "source": [
    "directory = \"C:/Users/sassi/Documents/DeepFakePhishing/Data/for-norm\" \n",
    "aggregate_audio_properties(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Files Found:\n",
      "\n",
      "Total number of duplicate files: 0\n"
     ]
    }
   ],
   "source": [
    "def hash_file(filepath, block_size=65536):\n",
    "    \"\"\"\n",
    "    Calculate the MD5 hash of a file.\n",
    "    Reads the file in chunks to handle large files.\n",
    "    \"\"\"\n",
    "    hasher = hashlib.md5()\n",
    "    try:\n",
    "        with open(filepath, 'rb') as file:\n",
    "            buf = file.read(block_size)\n",
    "            while buf:\n",
    "                hasher.update(buf)\n",
    "                buf = file.read(block_size)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {filepath}: {e}\")\n",
    "        return None\n",
    "    return hasher.hexdigest()\n",
    "\n",
    "def find_duplicates(directory):\n",
    "    \"\"\"\n",
    "    Walk through the directory (including subdirectories),\n",
    "    and group files by their MD5 hash.\n",
    "    \"\"\"\n",
    "    files_by_hash = {}\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            filepath = os.path.join(root, file)\n",
    "            file_hash = hash_file(filepath)\n",
    "            if file_hash is None:\n",
    "                continue  # Skip files that couldn't be read\n",
    "            files_by_hash.setdefault(file_hash, []).append(filepath)\n",
    "    return files_by_hash\n",
    "\n",
    "\n",
    "# Set the directory you want to search for duplicates\n",
    "directory = \"C:/Users/sassi/Documents/DeepFakePhishing/Data/for-norm/for-norm\"  # Replace with your target directory\n",
    "\n",
    "duplicates = find_duplicates(directory)\n",
    "duplicate_count = 0\n",
    "\n",
    "print(\"Duplicate Files Found:\")\n",
    "for file_hash, files in duplicates.items():\n",
    "    if len(files) > 1:\n",
    "        print(f\"\\nHash: {file_hash}\")\n",
    "        for f in files:\n",
    "            print(f\"  {f}\")\n",
    "        # Count duplicates: only count files beyond the first as duplicates\n",
    "        duplicate_count += len(files) - 1\n",
    "\n",
    "print(f\"\\nTotal number of duplicate files: {duplicate_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 empty files:\n"
     ]
    }
   ],
   "source": [
    "def find_empty_files(directory):\n",
    "    \"\"\"\n",
    "    Walk through the directory (including subdirectories),\n",
    "    and find files with 0 bytes size.\n",
    "    \"\"\"\n",
    "    empty_files = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            filepath = os.path.join(root, file)\n",
    "            if os.path.getsize(filepath) == 0:\n",
    "                empty_files.append(filepath)\n",
    "    return empty_files\n",
    "\n",
    "empty_files = find_empty_files(directory)\n",
    "\n",
    "print(f\"Found {len(empty_files)} empty files:\")\n",
    "for empty_file in empty_files:\n",
    "    print(empty_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
